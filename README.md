# Grantbot Backend

Backend API for grant application section generation. The application loads documents from a JSONL file, filters them by company and section type, ranks by text similarity, and combines them into generated sections.

## Features

- **Document Loading**: Loads documents from `./data/grantbot_vector_seed.jsonl` at startup
- **Section Generation**: Filters and ranks documents based on company_id, section_type, and text similarity
- **History Tracking**: Maintains in-memory history of all generation requests
- **Simple Retrieval**: Uses word overlap for document similarity (no external ML dependencies)
- **RESTful API**: FastAPI-based endpoints for generation and history

## Tech Stack

- Python 3.x
- FastAPI (HTTP framework)
- Uvicorn (ASGI server)
- Pydantic (data validation)
- python-dotenv (environment configuration)

## Project Structure

```
granbot-backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI app initialization
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ domain.py        # Internal domain models
â”‚   â”‚   â””â”€â”€ dto.py           # API request/response models
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ sections_controller.py  # API endpoints
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data_service.py         # Document loading
â”‚       â”œâ”€â”€ retrieval_service.py    # Document filtering/ranking
â”‚       â”œâ”€â”€ generation_service.py   # Text generation
â”‚       â””â”€â”€ history_service.py      # History tracking
â”œâ”€â”€ data/
â”‚   â””â”€â”€ grantbot_vector_seed.jsonl  # Source data
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_sections.py     # API tests
â”œâ”€â”€ .env.example             # Example environment variables
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md
```

## Project flow in shotcut (PL)

ğŸ‡µğŸ‡±
W main.py uruchamiamy gÅ‚Ã³wnÄ… aplikacjÄ™ FastAPI. Przy starcie aplikacji (w lifecycle) wczytujemy plik JSONL za pomocÄ… data_service.load_documents(). Ten plik peÅ‚ni rolÄ™ naszej â€œbazy danychâ€ â€“ wszystkie dokumenty sÄ… Å‚adowane do pamiÄ™ci. W main.py podpinamy teÅ¼ router z pliku sections_controller, dziÄ™ki czemu dostÄ™pne sÄ… endpointy API. Dodatkowo na poczÄ…tku wczytywany jest plik .env, Å¼eby mÃ³c korzystaÄ‡ z takich zmiennych jak DATA_PATH czy TOP_K.

W data_service mamy dwie rzeczy: metodÄ™ load_documents(), ktÃ³ra przy starcie wczytuje wszystkie rekordy z pliku .jsonl do pamiÄ™ci, oraz metodÄ™ pomocniczÄ… get_all_documents(), ktÃ³ra zwraca tÄ™ wczytanÄ… listÄ™ dokumentÃ³w innym czÄ™Å›ciom aplikacji.

W sections_controller definiujemy dwa endpointy:

POST /generate-section

GET /history/{company_id}

W POST /generate-section robimy caÅ‚y gÅ‚Ã³wny flow:

Pobieramy wszystkie dokumenty z pamiÄ™ci przez data_service.get_all_documents().

Sprawdzamy, czy coÅ› siÄ™ w ogÃ³le wczytaÅ‚o.

Przekazujemy te dokumenty do retrieval_service, ktÃ³ry wybiera najbardziej pasujÄ…ce dokumenty na podstawie: company_id, section_type oraz tekstu podanego w Å¼Ä…daniu.

Zwracamy tylko tyle najlepszych dokumentÃ³w, ile wynosi TOP_K ustawione w .env.

Wybrane dokumenty przekazujemy do generation_service, ktÃ³ry â€œÅ‚adnieâ€ skÅ‚ada je w jednÄ… odpowiedÅº tekstowÄ…. Tutaj moglibysmy uzyc llm do ulepszenia odpowiedzi.

Gotowy wynik zapisujemy w historii, wywoÅ‚ujÄ…c history_service.add_entry(...), ktÃ³ry dodaje nowy wpis do listy trzymanej w pamiÄ™ci (in-memory).

Zwracamy gotowÄ… odpowiedÅº do klienta (tekst + sources + metadata).

W GET /history/{company_id} po prostu pobieramy z history_service wpisy dla danej firmy metodÄ… get_by_company_id(...) i zwracamy je â€“ ta lista teÅ¼ jest trzymana w pamiÄ™ci i symuluje prostÄ… historiÄ™ wywoÅ‚aÅ„.

## Installation

1. **Clone the repository** (if not already done)

2. **Create and activate virtual environment**:

```bash
python3 -m venv venv
source venv/bin/activate
```

3. **Install dependencies**:

```bash
pip install -r requirements.txt
```

4. **Configure Environment**

   Create a `.env` file in the root directory of the project and add the following variables. This file is used to configure the application.

   ```
   DATA_PATH=./data/grantbot_vector_seed.jsonl
   TOP_K=3
   ```

## Running the Application

Start the server with uvicorn:

```bash
uvicorn app.main:app --reload
```

The API will be available at: `http://localhost:8000`

**Interactive API documentation**:

- Swagger UI: `http://localhost:8000/docs`

## API Endpoints

### 1. Generate Section

**POST** `/generate-section`

Generate a section by finding and combining relevant documents.

**Request Body**:

```json
{
  "company_id": "123",
  "section_type": "innovation_description",
  "text": "AI automation SaaS RAG generator"
}
```

**Response**:

```json
{
  "company_id": "123",
  "section_type": "innovation_description",
  "generated_text": "Based on 3 relevant document(s), here is the compiled content:\n\n--- Document 1 (ID: doc-123-innovation-1) ---\nGrantbot.ai to aplikacja SaaS...",
  "sources": [
    "doc-123-innovation-1",
    "doc-123-innovation-en-1",
    "doc-123-market-1"
  ],
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "created_at": "2025-11-11T10:30:00.000000Z"
}
```

### 2. Get History

**GET** `/history/{company_id}`

Retrieve generation history for a specific company.

**Response**:

```json
[
  {
    "request_id": "550e8400-e29b-41d4-a716-446655440000",
    "created_at": "2025-11-11T10:30:00.000000Z",
    "company_id": "123",
    "section_type": "innovation_description",
    "sources": [
      "doc-123-innovation-1",
      "doc-123-innovation-en-1",
      "doc-123-market-1"
    ]
  }
]
```

### 3. Health Check

**GET** `/`

Simple health check endpoint.

**Response**:

```json
{
  "message": "Grantbot Backend API",
  "status": "running"
}
```

## Data Source

The application reads documents from `./data/grantbot_vector_seed.jsonl`. Each line in this file is a JSON object with the following structure:

```json
{
  "id": "doc-123-innovation-1",
  "company_id": "123",
  "section_type": "innovation_description",
  "language": "pl",
  "tags": ["AI", "SaaS"],
  "source_type": "knowledge_base",
  "source_url": null,
  "created_at": "2025-09-18T07:03:20.577543Z",
  "text": "Document content here..."
}
```

## How It Works

1. **Startup**: Documents are loaded from the JSONL file into memory
2. **Request**: Client sends company_id, section_type, and query text
3. **Filter**: Documents are filtered by company_id and section_type
4. **Rank**: Filtered documents are ranked by word overlap similarity with query text
5. **Select**: Top K documents (default: 3) are selected
6. **Generate**: Selected documents are combined into a single text
7. **Track**: Request metadata is saved to in-memory history
8. **Response**: Generated text and metadata are returned to client

## Configuration

Configuration is managed via environment variables. If a `.env` file is present in the root directory, it will be loaded at startup. You can use `.env.example` as a template.

| Variable    | Default                             | Description                     |
| ----------- | ----------------------------------- | ------------------------------- |
| `DATA_PATH` | `./data/grantbot_vector_seed.jsonl` | Path to JSONL data file         |
| `TOP_K`     | `3`                                 | Number of documents to retrieve |

## Testing

Run tests with pytest:

```bash
pytest
```

Run with verbose output:

```bash
pytest -v
```

Run with coverage:

```bash
pytest --cov=app
```

## Important Notes

- **No LLM Integration**: This version uses simple text concatenation, no external AI models
- **In-Memory Storage**: History is stored in memory and lost on restart
- **No Persistence**: No database - all data comes from the JSONL file
- **Simple Similarity**: Uses word overlap counting, not advanced embeddings
- **Document Fallback**: If no documents match company_id + section_type, falls back to company_id only

## Future Enhancements

Potential improvements for future versions:

- LLM integration for better text generation
- Database for persistent history
- TF-IDF or embedding-based similarity
- Caching layer for repeated queries
- Authentication/authorization
- Rate limiting
- Docker containerization

## License

[Specify your license here]
